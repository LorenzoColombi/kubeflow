{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proviamo a farle in v2\n",
    "\n",
    "from tensorflow import keras\n",
    "from minio import Minio\n",
    "import numpy as np\n",
    "import json\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "import os\n",
    "from kfp.dsl import Output, Dataset, Model, Metrics, ClassificationMetrics\n",
    "\n",
    "\n",
    "@dsl.component( base_image=\"tensorflow/tensorflow\",packages_to_install=['minio'])\n",
    "def load_dataset(minio_url : str = \"10.152.183.148:9000\", minio_access_key : str =\"minio\", minio_secret : str =\"minio123\" , minio_bucket : str = \"mlpipeline\"):\n",
    "    '''\n",
    "    get dataset from minio and load it to minio separating X from Y and train from test\n",
    "    \n",
    "    Returns: number of example in training dataset, number of example in test dataset, dataset version.\n",
    "    '''\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        minio_url,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret,\n",
    "        secure=False\n",
    "    )\n",
    "   \n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # save to numpy file, store in Minio\n",
    "    np.save(\"tmp/x_train.npy\",x_train)\n",
    "    minio_client.fput_object(minio_bucket,\"x_train\",\"tmp/x_train.npy\")\n",
    "\n",
    "    np.save(\"tmp/y_train.npy\",y_train)\n",
    "    minio_client.fput_object(minio_bucket,\"y_train\",\"tmp/y_train.npy\")\n",
    "\n",
    "    np.save(\"tmp/x_test.npy\",x_test)\n",
    "    minio_client.fput_object(minio_bucket,\"x_test\",\"tmp/x_test.npy\")\n",
    "\n",
    "    np.save(\"tmp/y_test.npy\",y_test)\n",
    "    minio_client.fput_object(minio_bucket,\"y_test\",\"tmp/y_test.npy\")\n",
    "\n",
    "    dataset_version = \"1.0\"\n",
    "\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    print(\"Success!\")\n",
    "\n",
    "@dsl.component(base_image=\"tensorflow/tensorflow\", packages_to_install=['minio'])\n",
    "def preprocessing(\n",
    "        metrics : Output[Metrics],\n",
    "        minio_url : str = \"10.152.183.148:9000\", minio_access_key : str =\"minio\", minio_secret : str =\"minio123\" , minio_bucket : str = \"mlpipeline\"\n",
    "        \n",
    "):\n",
    "    '''\n",
    "    get data from minio and reshape this way: len,28,28 -> len,28,28,1 and load (again) to minio\n",
    "    one channel because it's a grey scale image\n",
    "    '''\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        minio_url,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret,\n",
    "        secure=False\n",
    "    )\n",
    "    print(\"getting data from minio\")\n",
    "    \n",
    "    # load data from minio\n",
    "    minio_client.fget_object(minio_bucket,\"x_train\",\"tmp/x_train.npy\")\n",
    "    x_train = np.load(\"tmp/x_train.npy\") \n",
    "    minio_client.fget_object(minio_bucket,\"x_test\",\"tmp/x_test.npy\")\n",
    "    x_test = np.load(\"tmp/x_test.npy\")\n",
    "    \n",
    "    # reshaping the data\n",
    "    # reshaping pixels in a 28x28px image with greyscale, canal = 1. This is needed for the Keras API\n",
    "    x_train = x_train.reshape(-1,28,28,1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "    # normalizing the data\n",
    "    # each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "\n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    \n",
    "    metrics.log_metric(\"Len x_train\", x_train.shape[0])\n",
    "    metrics.log_metric(\"Len y_train\", x_test.shape[0])\n",
    "   \n",
    "    \n",
    "    # save data in minio\n",
    "    np.save(\"tmp/x_train.npy\",x_train)\n",
    "    minio_client.fput_object(minio_bucket,\"x_train\",\"tmp/x_train.npy\")\n",
    "    np.save(\"tmp/x_test.npy\",x_test)\n",
    "    minio_client.fput_object(minio_bucket,\"x_test\",\"tmp/x_test.npy\")\n",
    "    \n",
    "    print(\"Success\")\n",
    "\n",
    "@dsl.component(base_image=\"tensorflow/tensorflow\", packages_to_install=['minio'])\n",
    "def model_building(minio_url : str = \"10.152.183.148:9000\", minio_access_key : str =\"minio\", minio_secret : str =\"minio123\" , minio_bucket : str = \"mlpipeline\"):\n",
    "    '''\n",
    "    Define the model and load it (not yet compiled to minio)\n",
    "    This way it's more simple to change the model architecture and all the steps and indipendent\n",
    "    '''\n",
    "    from tensorflow import keras\n",
    "    import tensorflow as tf\n",
    "    from minio import Minio\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        minio_url,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    #model definition\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    summary = model.summary()\n",
    "    \n",
    "    #saving model\n",
    "    model.save('./tmp/model.keras')\n",
    "    #upload_local_directory_to_minio(\"./tmp/model\",minio_bucket,\"models/detect-digits-notcompiled/\")\n",
    "    minio_client.fput_object(minio_bucket, \"models/detect-digits-notcompiled/model.keras\", \"./tmp/model.keras\")\n",
    "    \n",
    "    print(\"Success\")\n",
    "    \n",
    "@dsl.component(packages_to_install=['minio','kubeflow-katib'])\n",
    "def hyperparameter_search(minio_url : str = \"10.152.183.148:9000\", minio_access_key : str =\"minio\", minio_secret : str =\"minio123\" , minio_bucket : str = \"mlpipeline\") -> dict:\n",
    "    '''\n",
    "    Use Katib for hyperparameter tuning\n",
    "    '''\n",
    "    import kubeflow.katib as katib\n",
    "    import ast\n",
    "    import sys\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    \n",
    "    def katib_search_supportfunc(parameters : dict):\n",
    "        \"\"\"\n",
    "        Load model from minio, compile a fit\n",
    "        Used by katib to find the best hyperparameter\n",
    "        \"\"\"\n",
    "        from tensorflow import keras\n",
    "        import tensorflow as tf\n",
    "        from minio import Minio\n",
    "        import time\n",
    "        import numpy as np\n",
    "\n",
    "        # Get HyperParameters from the input params dict.\n",
    "        lr = float(parameters[\"lr\"])\n",
    "        num_epoch = int(parameters[\"num_epoch\"])\n",
    "\n",
    "        print(\"lr:\", lr)\n",
    "        print(\"num_epoch:\",num_epoch)\n",
    "\n",
    "        minio_client = Minio(\n",
    "            \"10.152.183.148:9000\",\n",
    "            access_key=\"minio\",\n",
    "            secret_key=\"minio123\",\n",
    "            secure=False\n",
    "        )\n",
    "        minio_bucket = \"mlpipeline\"\n",
    "        print(\"getting data from minio\")\n",
    "\n",
    "        #model loading from minio\n",
    "        minio_client.fget_object(minio_bucket, \"models/detect-digits-notcompiled/model.keras\", \"./tmp/model_from_minio.keras\")\n",
    "        model = keras.models.load_model(\"./tmp/model_from_minio.keras\")\n",
    "\n",
    "\n",
    "        #compile the model - we want to have a binary outcome\n",
    "        print(\"compiling model\")\n",
    "        model.compile(tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        #load dataset from minio\n",
    "        minio_client.fget_object(minio_bucket,\"x_train\",\"tmp/x_train.npy\")\n",
    "        x_train = np.load(\"tmp/x_train.npy\")\n",
    "        minio_client.fget_object(minio_bucket,\"y_train\",\"tmp/y_train.npy\")\n",
    "        y_train = np.load(\"tmp/y_train.npy\")\n",
    "        minio_client.fget_object(minio_bucket,\"x_test\",\"tmp/x_test.npy\")\n",
    "        x_test = np.load(\"tmp/x_test.npy\") \n",
    "        minio_client.fget_object(minio_bucket,\"y_test\",\"tmp/y_test.npy\")\n",
    "        y_test = np.load(\"tmp/y_test.npy\")\n",
    "\n",
    "\n",
    "        #fit the model and return the history while training\n",
    "        history = model.fit(\n",
    "          x=x_train,\n",
    "          y=y_train,\n",
    "          epochs=num_epoch,\n",
    "          batch_size=20,\n",
    "        )\n",
    "\n",
    "        # Test the model against the test dataset\n",
    "        # Returns the loss value & metrics values for the model in test mode.\n",
    "        model_loss, model_accuracy = model.evaluate(x=x_test,y=y_test)\n",
    "\n",
    "        #output the metrics to stdout\n",
    "        loss_str = \"loss=\"+str(model_loss)\n",
    "        acc_str = \"accuracy=\"+str(model_accuracy)\n",
    "        print(loss_str)\n",
    "        print(acc_str)\n",
    "\n",
    "    # Set parameters with their distribution for HyperParameter Tuning with Katib.\n",
    "    parameters = {\n",
    "        \"lr\": katib.search.double(min=0.1, max=0.2),\n",
    "        \"num_epoch\": katib.search.int(min=1, max=2),\n",
    "    }\n",
    "\n",
    "    # Start the Katib Experiment.\n",
    "    now = datetime.now() # current date and time\n",
    "    date_time = now.strftime(\"-%m-%d-%Y--%H-%M-%S\")\n",
    "    exp_name = \"tune-mnist-example\" + date_time\n",
    "    katib_client = katib.KatibClient()\n",
    "    \n",
    "    \n",
    "    #Hyperparamter tuning\n",
    "    katib_client.tune(\n",
    "        name=exp_name,\n",
    "        packages_to_install = [\"minio\"],\n",
    "        base_image = \"tensorflow/tensorflow\",\n",
    "        objective=katib_search_supportfunc, # Objective function.\n",
    "        parameters=parameters, # HyperParameters to tune.\n",
    "        algorithm_name=\"cmaes\", # Alorithm to use.\n",
    "        objective_metric_name=\"accuracy\", # Katib is going to optimize \"accuracy\".\n",
    "        additional_metric_names=[\"loss\"], # Katib is going to collect these metrics in addition to the objective metric.\n",
    "        max_trial_count=2, # Trial Threshold (max number of training)\n",
    "        parallel_trial_count=2)\n",
    "    \n",
    "    #Getting the best parameter\n",
    "    status = katib_client.is_experiment_succeeded(exp_name)\n",
    "    print(f\"Katib Experiment is Succeeded: {status}\\n\")\n",
    "    \n",
    "    while(str(status)==\"False\"):\n",
    "        print(\"Waiting for experiment end...\")\n",
    "        time.sleep(10)\n",
    "        status = katib_client.is_experiment_succeeded(exp_name)\n",
    "    print(\"Exeperiment ended\")\n",
    "\n",
    "    best_hps = katib_client.get_optimal_hyperparameters(exp_name)\n",
    "\n",
    "    if best_hps != None:\n",
    "        print(\"Current Optimal Trial\\n\")\n",
    "        print(best_hps)\n",
    "\n",
    "        # Convert the input string to a dictionary\n",
    "        result_dict = ast.literal_eval(str(best_hps))\n",
    "        \n",
    "        # Extracting useful information\n",
    "        result_list = result_dict['parameter_assignments']\n",
    "\n",
    "        result={}\n",
    "        for i in result_list:\n",
    "            result[i[\"name\"]] = i[\"value\"]\n",
    "\n",
    "        print(\"Best HPs extracted:\",result)\n",
    "    else:\n",
    "        print(\"Can't get best hyperparameter error - Exit\")\n",
    "        sys.exit()\n",
    "    \n",
    "    return result\n",
    "\n",
    "@dsl.component(base_image=\"tensorflow/tensorflow\", packages_to_install=['minio','scikit-learn'])\n",
    "def model_training(\n",
    "    metrics: Output[Metrics], classification_metrics: Output[ClassificationMetrics],\n",
    "    hyperparameters : dict, minio_url : str = \"10.152.183.148:9000\", minio_access_key : str =\"minio\", minio_secret : str =\"minio123\" , minio_bucket : str = \"mlpipeline\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Build the model with Keras API\n",
    "    Export model parameters\n",
    "    \"\"\"\n",
    "    from tensorflow import keras\n",
    "    import tensorflow as tf\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import glob\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "   \n",
    "    \n",
    "    #reading best hyperparameters from katib\n",
    "    lr=float(hyperparameters[\"lr\"])\n",
    "    no_epochs = int(hyperparameters[\"num_epoch\"])\n",
    "    \n",
    "    minio_client = Minio(\n",
    "        minio_url,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret,\n",
    "        secure=False\n",
    "    )\n",
    "    print(\"getting data from minio\")\n",
    "    \n",
    "    #model loading from minio\n",
    "    minio_client.fget_object(minio_bucket, \"models/detect-digits-notcompiled/model.keras\", \"./tmp/model_from_minio.keras\")\n",
    "    model = keras.models.load_model(\"./tmp/model_from_minio.keras\")\n",
    "    model.summary()\n",
    "    \n",
    "    #compile the model - we want to have a binary outcome\n",
    "    model.compile(tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #load dataset from minio\n",
    "    minio_client.fget_object(minio_bucket,\"x_train\",\"tmp/x_train.npy\")\n",
    "    x_train = np.load(\"tmp/x_train.npy\")\n",
    "    minio_client.fget_object(minio_bucket,\"y_train\",\"tmp/y_train.npy\")\n",
    "    y_train = np.load(\"tmp/y_train.npy\")\n",
    "    minio_client.fget_object(minio_bucket,\"x_test\",\"tmp/x_test.npy\")\n",
    "    x_test = np.load(\"tmp/x_test.npy\") \n",
    "    minio_client.fget_object(minio_bucket,\"y_test\",\"tmp/y_test.npy\")\n",
    "    y_test = np.load(\"tmp/y_test.npy\")\n",
    "    \n",
    "    \n",
    "    #fit the model and return the history while training\n",
    "    history = model.fit(\n",
    "      x=x_train,\n",
    "      y=y_train,\n",
    "      epochs=no_epochs,\n",
    "      batch_size=20,\n",
    "    )\n",
    "\n",
    "    y_predict = model.predict(x=x_test)\n",
    "    y_predict = np.argmax(y_predict, axis=1)\n",
    "    \n",
    "    \n",
    "    # Test the model against the test dataset\n",
    "    # Returns the loss value & metrics values for the model in test mode.\n",
    "    model_loss, model_accuracy = model.evaluate(x=x_test,y=y_test)\n",
    "   \n",
    "    cmatrix = confusion_matrix(y_test, y_predict)\n",
    "    cmatrix = cmatrix.tolist()\n",
    "    print(len(cmatrix))\n",
    "    print(len(cmatrix[0]))\n",
    "   \n",
    "    \n",
    "    #Kubeflox metrics export\n",
    "    metrics.log_metric(\"Test loss\", model_loss)\n",
    "    metrics.log_metric(\"Test accuracy\", model_accuracy)\n",
    "          \n",
    "        \n",
    "    numbers_list = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    classification_metrics.log_confusion_matrix(numbers_list,cmatrix)\n",
    "    #build a confusion matrix\n",
    "    \n",
    "    # Generates output predictions for the input samples.\n",
    "    \n",
    "    # the prediction outputs 10 values, we take the index number of the highest value, which is the prediction of the model\n",
    "\n",
    "    #save trained model to minio\n",
    "    keras.models.save_model(model,\"tmp/detect-digits\")\n",
    "\n",
    "    def upload_local_directory_to_minio(local_path, bucket_name, minio_path):\n",
    "        assert os.path.isdir(local_path)\n",
    "\n",
    "        for local_file in glob.glob(local_path + '/**'):\n",
    "            if not os.path.isfile(local_file):\n",
    "                upload_local_directory_to_minio(\n",
    "                    local_file, bucket_name, minio_path + \"/\" + os.path.basename(local_file))\n",
    "            else:\n",
    "                remote_path = os.path.join(minio_path, local_file[1 + len(local_path):])\n",
    "                minio_client.fput_object(bucket_name, remote_path, local_file)\n",
    "\n",
    "    upload_local_directory_to_minio(\"tmp/detect-digits\",minio_bucket,\"models/detect-digits/1\") # 1 for version 1\n",
    "\n",
    "    print(\"Saved trained model to minIO\")\n",
    "    print(\"Success\")\n",
    "    \n",
    "@dsl.component(packages_to_install=['kserve','kubernetes'])\n",
    "def model_serving():\n",
    "    \"\"\"\n",
    "    Create kserve instance\n",
    "    \"\"\"\n",
    "    from kubernetes import client \n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import utils\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1TFServingSpec\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    namespace = utils.get_default_target_namespace()\n",
    "\n",
    "    now = datetime.now()\n",
    "    #v = now.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "\n",
    "    #name='digits-recognizer-{}'.format(v)\n",
    "    name=\"digits-recognizer\"\n",
    "    kserve_version='v1beta1'\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "\n",
    "    isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                   kind=constants.KSERVE_KIND,\n",
    "                                   metadata=client.V1ObjectMeta(\n",
    "                                       name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}),\n",
    "                                   spec=V1beta1InferenceServiceSpec(\n",
    "                                   predictor=V1beta1PredictorSpec(\n",
    "                                       service_account_name=\"sa-minio-kserve\",\n",
    "                                       tensorflow=(V1beta1TFServingSpec(\n",
    "                                           storage_uri=\"s3://mlpipeline/models/detect-digits/\"))))\n",
    "    )\n",
    "\n",
    "    KServe = KServeClient()\n",
    "    #provo a eliminare il deploy se esiste\n",
    "    try:\n",
    "        KServe.delete(name=name, namespace=namespace)\n",
    "        print(\"Modello precedente eliminato\")\n",
    "    except:\n",
    "        print(\"Non posso eliminare\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    KServe.create(isvc)\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='digits-recognizer-pipeline',\n",
    "    description='Detect digits'\n",
    ")\n",
    "def mnist_pipeline(minio_url : str = \"10.152.183.148:9000\", minio_access_key : str =\"minio\", minio_secret : str =\"minio123\" , minio_bucket : str = \"mlpipeline\"):\n",
    "    step1 = load_dataset(minio_url =minio_url, minio_access_key = minio_access_key, minio_secret = minio_secret , minio_bucket = minio_bucket)\n",
    "    step2 = preprocessing(minio_url =minio_url, minio_access_key = minio_access_key, minio_secret = minio_secret , minio_bucket = minio_bucket)\n",
    "    step3 = model_building(minio_url =minio_url, minio_access_key = minio_access_key, minio_secret = minio_secret , minio_bucket = minio_bucket)\n",
    "    step4 = hyperparameter_search(minio_url =minio_url, minio_access_key = minio_access_key, minio_secret = minio_secret , minio_bucket = minio_bucket)\n",
    "    step5 = model_training(hyperparameters= step4.output,minio_url =minio_url, minio_access_key = minio_access_key, minio_secret = minio_secret , minio_bucket = minio_bucket)\n",
    "    step6 = model_serving()\n",
    "    \n",
    "    \n",
    "    step2.after(step1)\n",
    "    step3.after(step2)\n",
    "    step4.after(step3)\n",
    "    step5.after(step4)\n",
    "    step6.after(step5)\n",
    " \n",
    "#main\n",
    "#minio config \n",
    "minio_url=\"10.152.183.148:9000\"\n",
    "minio_access_key=\"minio\"\n",
    "minio_secret=\"minio123\"\n",
    "\n",
    "print(\"start\")\n",
    "\n",
    "arguments = {\n",
    "    \"minio_url\":\"10.152.183.148:9000\",\n",
    "    \"minio_access_key\":\"minio\",\n",
    "    \"minio_secret\":\"minio123\",\n",
    "    \"minio_bucket\" : \"mlpipeline\"   \n",
    "            }\n",
    "\n",
    "with open(os.environ['KF_PIPELINES_SA_TOKEN_PATH'], \"r\") as f:\n",
    "    TOKEN = f.read()\n",
    "\n",
    "client = kfp.Client(\n",
    "    existing_token=TOKEN,\n",
    "    host='http://ml-pipeline.kubeflow.svc.cluster.local:8888',\n",
    ")\n",
    "namespace=\"kubeflow-user-example-com\"\n",
    "kfp.compiler.Compiler().compile(pipeline_func=mnist_pipeline,package_path='./mnist-pipeline.yaml')\n",
    "\n",
    "#client.create_run_from_pipeline_func(mnist_pipeline,arguments=arguments,experiment_name=\"test\",namespace=\"kubeflow-user-example-com\",enable_caching=False)\n",
    "#client.upload_pipeline(pipeline_package_path='output_test.yaml',pipeline_version_name=\"0.4\",pipeline_name=\"mnist video tutorial\")\n",
    "#client.upload_pipeline(pipeline_package_path='./mnist-pipeline.yaml',pipeline_name=\"mnist video tutorial\",namespace = namespace)\n",
    "client.upload_pipeline_version(pipeline_package_path='./mnist-pipeline.yaml',pipeline_name=\"mnist video tutorial\",pipeline_version_name= \"2 uso artifact store\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
